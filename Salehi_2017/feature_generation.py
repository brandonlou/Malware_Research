import csv
import multiprocessing as mp
import os
import sys


# Lock to access the global feature set.
lock = mp.Lock()


def process_report(input_dir: str, filename: str, features):
    with open(input_dir + '/' + filename) as infile:
        try:
            lines = infile.readlines()
        except:
            print('Error: Cannot read', filename)
            return
    
    # Skip first line because it tells the verdict and isn't an API call.
    for i in range(1, len(lines)):
        lines[i] = lines[i].strip() # Remove the newline at the end of string.
        features[lines[i]] = None
    
    print('Read features:', filename)


def generate_feature(input_dir, filename, ordered_features, data):
    with open(input_dir + '/' + filename) as infile:
        try:
            lines = infile.readlines()
        except:
            return
    
    for i in range(len(lines)):
        lines[i] = lines[i].strip()
    
    verdict = lines[0]

    vector = str()
    for feature in ordered_features:
        if feature in lines[1:]:
            vector += '1'
        else:
            vector += '0'

    data.append((vector, verdict))
    
    print('Success:', filename)


def main():
    if len(sys.argv) != 3:
        print('USAGE: %s [input directory] [output file]' % sys.argv[0])
        exit()

    input_dir = sys.argv[1]
    output_file = sys.argv[2]

    # Delete file before appending to it to overwrite.
    if os.path.exists(output_file):
        os.remove(output_file)

    manager = mp.Manager()
    features = manager.dict()

    pool = mp.Pool()
    for filename in os.listdir(input_dir):
        pool.apply_async(process_report, args=(input_dir, filename, features))
    pool.close()
    pool.join()

    # Convert set to tuple because it's ordered.
    ordered_features = tuple(features.keys())

    # Multiprocess-shared list of tuples to store all binary features and labels.
    data = manager.list()

    # Reset pool.
    pool = mp.Pool()

    for filename in os.listdir(input_dir):
        pool.apply_async(generate_feature, args=(input_dir, filename, ordered_features, data))
    pool.close()
    pool.join()

    # Write all binary features and their label to a CSV file.
    with open(output_file, 'wt') as csv_file:
        csv_writer = csv.writer(csv_file)
        for entry in data:
            csv_writer.writerow([entry[0], entry[1]])

if __name__ == "__main__":
    main()
