import os
import pickle
import sys
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score
from utils.colors import Colors

def main():
    if len(sys.argv) != 5:
        print(f'Usage: python {sys.argv[0]} <input dir> <feature pkl> <indices pkl> <model pkl>')
        exit()

    # Load top features to use.
    with open(sys.argv[2], 'rb') as features_file:
        all_features = pickle.load(features_file)
        print(f'{Colors.YELLOW}Info: Loaded {sys.argv[2]}{Colors.ENDC}')
    with open(sys.argv[3], 'rb') as indices_file:
        feature_indices = pickle.load(indices_file)
        print(f'{Colors.YELLOW}Info: Loaded {sys.argv[3]}{Colors.ENDC}')

    selected_features = list()
    for index in feature_indices:
        selected_features.append(all_features[index])

    X_data = list()
    y_data = list()

    # Load all preprocessed files and build feature vectors.
    input_dir = sys.argv[1]
    for filename in os.listdir(input_dir):
        with open(f'{input_dir}/{filename}') as infile:
            try:
                lines = infile.read().splitlines()
            except:
                continue

        # Get the verdict of the report.
        verdict = lines[0]
        if verdict not in ('0', '1'):
            print(f'{Colors.RED}Error: First line of {filename} not 0 or 1{Colors.ENDC}')
            exit()

        vector = list()
        for feature in selected_features:
            vector.append(1 if feature in lines[1:] else 0)

        X_data.append(vector)
        y_data.append(int(verdict))

    # Load trained model from disk.
    with open(sys.argv[4], 'rb') as model_file:
        model = pickle.load(model_file)
        print(f'{Colors.YELLOW}Info: Loaded {sys.argv[4]}{Colors.ENDC}')
    y_pred = model.predict(X_data)

    # Calculate metrics.
    accuracy  = accuracy_score(y_data, y_pred)
    precision = precision_score(y_data, y_pred)
    recall    = recall_score(y_data, y_pred)
    auc       = roc_auc_score(y_data, y_pred)
    num_fp    = confusion_matrix(y_data, y_pred).ravel()[1]
    f1        = f1_score(y_data, y_pred)

    # Print performance.
    print(f'Accuracy: {accuracy:.3f}')
    print(f'Precision: {precision:.3f}')
    print(f'Recall: {recall:.3f}')
    print(f'AUC: {auc:.3f}')
    print(f'Number false positives: {num_fp:.3f}')
    print(f'F1 Score: {f1:.3f}')


if __name__ == "__main__":
    main()
