import json
import multiprocessing as mp
import os
import sys
from utils.colors import Colors
from utils.valid_api import is_valid_api


MIN_API_CALLS = 400
MAX_ARG_LENGTH = 500


def process_report(filename: str, input_dir: str, output_dir: str, verdict:int):
    with open(input_dir + '/' + filename, 'r') as cuckoo_report:
        try:
            data = json.load(cuckoo_report)
        except:
            print(f'{Colors.RED}Error: Could not parse {filename} as JSON{Colors.ENDC}')
            return

    behavior = data.get('behavior')
    if behavior is None:
        print(f'{Colors.RED}Error: {filename} has no behavior section{Colors.ENDC}')
        return

    processes = behavior.get('processes')
    if processes is None:
        print(f'{Colors.RED}Error: {filename} has no processes section{Colors.ENDC}')
        return

    # Stores all features found in this report.
    feature_set = set()

    # Store the number of API calls in this report.
    num_api_calls = 0

    for process in processes:
        for call in process.get('calls'):

            api_name = call.get('api')
            if not is_valid_api(api_name):
                continue

            return_value = call.get('return_value')
            if return_value is None:
                print(f'{Colors.YELLOW}Warning: {filename} has an API call with no return value{Colors.ENDC}')
                continue

            arguments = call.get('arguments')
            if arguments is None:
                print(f'{Colors.YELLOW}Warning: {filename} has an API call with no arguments{Colors.ENDC}')
                continue

            # Alphabeticalize keys to be consistent.
            keys = sorted(arguments)

            if len(arguments) == 0:
                feature_set.add('%s%s' % (api_name, return_value))
            else:
                for arg_index in range(len(arguments)):
                    arg_value = arguments[keys[arg_index]]
                    arg_value = str(arg_value).encode('latin-1', 'ignore').decode('latin-1')
                    # Limit arguments to the maximum length.
                    arg_value = arg_value[:MAX_ARG_LENGTH]
                    # Remove all new lines in arguments.
                    arg_value = ''.join(arg_value.splitlines())
                    feature_set.add('%s%d%s%s' % (api_name, arg_index + 1, arg_value, return_value))

            num_api_calls += 1

    if num_api_calls <= MIN_API_CALLS:
        print(f'{Colors.YELLOW}Skip: {filename} has less than {MIN_API_CALLS} API calls{Colors.ENDC}')
        return

    output_file = '%s/%s_%d.txt' % (output_dir, filename, verdict)
    with open(output_file, 'wt') as outfile:

        # Write 0 (benign) or 1 (malicious) as the first line of the output file.
        outfile.write('%d\n' % verdict)

        # Write a feature each line.
        for feature in feature_set:
            outfile.write('%s\n' % feature)

    print(f'{Colors.GREEN}Success: {filename}{Colors.ENDC}')


def main():
    if len(sys.argv) != 4:
        print(f'Usage: python {sys.argv[0]} <input dir> <output dir> <0/1>')
        exit()

    input_dir = sys.argv[1]
    output_dir = sys.argv[2]

    if sys.argv[3] == '1':
        verdict = 1 # Malicious.
    elif sys.argv[3] == '0':
        verdict = 0 # Benign.
    else:
        print(f'Usage: python {sys.argv[0]} <input dir> <output dir> <0/1>')
        exit()

    pool = mp.Pool(mp.cpu_count()) # Use all CPU cores.

    for filename in os.listdir(input_dir):
        pool.apply_async(process_report,
                        (filename, input_dir, output_dir, verdict))

    pool.close() # Close the pool for new tasks.
    pool.join()  # Wait for all tasks to complete.


if __name__ == "__main__":
    main()
