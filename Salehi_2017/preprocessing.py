import json
import multiprocessing as mp
import os
import sys
from utils.valid_api import is_valid_api


MIN_API_CALLS = 100
MAX_ARG_LENGTH = 500


def process_report(filename: str, input_dir: str, output_dir: str, verdict:int):
    with open(input_dir + '/' + filename, 'r') as cuckoo_report:
        try:
            data = json.load(cuckoo_report)
        except:
            print('ERROR: Could not parse %s as JSON' % filename)
            return
    
    behavior = data.get('behavior')
    if behavior is None:
        print('ERROR: %s has no behavior section' % filename)
        return

    processes = behavior.get('processes')
    if processes is None:
        print('Error: %s has no processes section' % filename)
        return

    # Stores all features found in this report.
    feature_set = set()

    for process in processes:
        for call in process.get('calls'):

            api_name = call.get('api')
            # if api_name is None:
            #     print('Warning: %s has an API call with no API name' % filename)
            #     continue
            if not is_valid_api(api_name):
                continue

            return_value = call.get('return_value')
            if return_value is None:
                print('Warning: %s has an API call with no return value' % filename)
                continue

            arguments = call.get('arguments')
            if arguments is None:
                print('Warning: %s has an API call with no arguments' % filename)
                continue

            if len(arguments) == 0:
                feature_set.add('%s...%s\n' % (api_name, return_value))

            else:
                for arg_index in range(len(arguments)):
                    arg_value = list(arguments.values())[arg_index] # TODO: Alphabeticalize keys to be consistent?
                    arg_value = str(arg_value).encode('latin-1', 'ignore').decode('latin-1')
                    arg_value = arg_value[:MAX_ARG_LENGTH] # Limit arguments to 500 characters.
                    feature_set.add('%s.%d.%s.%s\n' % (api_name, arg_index + 1, arg_value, return_value))

    if len(feature_set) < MIN_API_CALLS:
        print('ERROR: %s does not have enough API calls' % filename)
        return

    output_file = '%s/%s_%d.txt' % (output_dir, filename, verdict)
    with open(output_file, 'wt') as outfile:

        # Write 0 (benign) or 1 (malicious) as the first line of the output file.
        outfile.write('%d\n' % verdict)

        # Write a feature each line.
        for feature in feature_set:
            outfile.write(feature)

    print('Success: %s' % filename)


def main():
    if len(sys.argv) != 4:
        print('Usage: python3 %s [reports directory] [0/1] [output directory]' % sys.argv[0])
        exit()

    input_dir = sys.argv[1]

    if sys.argv[2] == '1':
        verdict = 1 # Malicious.
    elif sys.argv[2] == '0':
        verdict = 0 # Benign.
    else:
        print('Usage: python3 %s [reports directory] [0/1] [output directory]' % sys.argv[0])
        exit()

    output_dir = sys.argv[3]

    pool = mp.Pool(mp.cpu_count()) # Use all CPU cores.

    for filename in os.listdir(input_dir):
        pool.apply_async(process_report, args=(filename, input_dir, output_dir, verdict))

    pool.close() # Close the pool for new tasks.
    pool.join()  # Wait for all tasks to complete.


if __name__ == "__main__":
    main()
