import csv
import sys
from skfeature.function.similarity_based import fisher_score
from sklearn.model_selection import KFold, RepeatedStratifiedKFold, cross_val_score
from sklearn import svm
from sklearn.feature_selection import RFE
from sklearn.pipeline import Pipeline

if len(sys.argv) != 2:
    print('USAGE: %s [data file]' % sys.argv[0])
    exit()

X_data = list()
y_data = list()

with open(sys.argv[1], 'r') as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for row in csv_reader:
        vector = [int(char) for char in row[0]]
        verdict = int(row[1])
        X_data.append(vector)
        y_data.append(verdict)

# Fisher score: https://jundongl.github.io/scikit-feature/tutorial.html
score = fisher_score.fisher_score(X_data, y_data)
ranked_indices = fisher_score.feature_ranking(score)
max_num_features = 1000
ranked_indices = sorted(ranked_indices[:max_num_features])
for i in range(len(X_data)):
    X_data[i] = [X_data[i][j] for j in ranked_indices]

rfe = RFE(estimator=svm.SVC(), n_features_to_select=500)
model = svm.SVC()
pipeline = Pipeline(steps=[('s', rfe), ('m', model)])

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)
n_scores = cross_val_score(pipeline, X_data, y_data, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')

print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

# kf = KFold(n_splits=10, shuffle=True, random_state=3)

# for train_indices, test_indices in kf.split(X_data):
#     X_train = X_data[train_indices]
#     X_test  = X_data[test_indices]
#     y_train = y_data[train_indices]
#     y_test  = y_data[test_indices]




# TODO:
# Do SVM-RFE
# 10-fold cross validation
# ^ 2 rounds of this
# Classification algo: Bayesian logistic regression (BLR)
