import csv
import pickle
import sys
from numpy import mean, std
from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score
from sklearn import svm
from sklearn.feature_selection import RFE
from sklearn.pipeline import Pipeline
from utils.blr import EBLogisticRegression, VBLogisticRegression


RFE_NUM_FEATURES = 380 # Number of features in our work.
NUM_FOLDS = 10


if len(sys.argv) != 2:
    print('USAGE: python3 %s [data file]' % sys.argv[0])
    exit()

X_data = list()
y_data = list()

# Get data from CSV file in the format (x, y).
with open(sys.argv[1], 'rt') as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for row in csv_reader:
        vector = list(map(int, row[0])) 
        verdict = int(row[1])
        X_data.append(vector)
        y_data.append(verdict)

# Apply SVM-RFE
rfe = RFE(estimator=svm.LinearSVC(), n_features_to_select=RFE_NUM_FEATURES)

# Classify using Bayesian logistic regression.
classifier = EBLogisticRegression()
pipeline = Pipeline(steps=[('s', rfe), ('c', classifier)])

# Do 10-fold cross validation two times to prevent overfitting.
cv = RepeatedStratifiedKFold(n_splits=NUM_FOLDS, n_repeats=2, random_state=1)
scores = cross_val_score(pipeline, X_data, y_data, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')

# Save model.
model_filename = 'trained_model.sav'
pickle.dump(pipeline, open(model_filename, 'wb'))

print('Mean Accuracy: %.3f' % mean(scores))
print('Standard Deviation: %.3f' % std(scores))

