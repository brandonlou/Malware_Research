import csv
import numpy as np
import pickle
import sys
from scipy.sparse import diags, lil_matrix
from sklearn.metrics.pairwise import pairwise_distances


FISHER_NUM_FEATURES = 1000


def construct_W(X, **kwargs):

    # default metric is 'cosine'
    if 'metric' not in kwargs.keys():
        kwargs['metric'] = 'cosine'

    # default neighbor mode is 'knn' and default neighbor size is 5
    if 'neighbor_mode' not in kwargs.keys():
        kwargs['neighbor_mode'] = 'knn'
    if kwargs['neighbor_mode'] == 'knn' and 'k' not in kwargs.keys():
        kwargs['k'] = 5
    if kwargs['neighbor_mode'] == 'supervised' and 'k' not in kwargs.keys():
        kwargs['k'] = 5
    if kwargs['neighbor_mode'] == 'supervised' and 'y' not in kwargs.keys():
        print ('Warning: label is required in the supervised neighborMode!!!')
        exit(0)

    # default weight mode is 'binary', default t in heat kernel mode is 1
    if 'weight_mode' not in kwargs.keys():
        kwargs['weight_mode'] = 'binary'
    if kwargs['weight_mode'] == 'heat_kernel':
        if kwargs['metric'] != 'euclidean':
            kwargs['metric'] = 'euclidean'
        if 't' not in kwargs.keys():
            kwargs['t'] = 1
    elif kwargs['weight_mode'] == 'cosine':
        if kwargs['metric'] != 'cosine':
            kwargs['metric'] = 'cosine'

    # default fisher_score and reliefF mode are 'false'
    if 'fisher_score' not in kwargs.keys():
        kwargs['fisher_score'] = False
    if 'reliefF' not in kwargs.keys():
        kwargs['reliefF'] = False

    n_samples, n_features = np.shape(X)

    # choose supervised neighborMode
    k = kwargs['k']
    # get true labels and the number of classes
    y = kwargs['y']
    label = np.unique(y)
    n_classes = np.unique(y).size
    # construct the weight matrix W in a fisherScore way, W_ij = 1/n_l if yi = yj = l, otherwise W_ij = 0
    if kwargs['fisher_score'] is True:
        W = lil_matrix((n_samples, n_samples))
        for i in range(n_classes):
            class_idx = (y == label[i])
            class_idx_all = (class_idx[:, np.newaxis] & class_idx[np.newaxis, :])
            W[class_idx_all] = 1.0/np.sum(np.sum(class_idx))
        return W


def fisher_score(X, y):
    # Construct weight matrix W in a fisherScore way
    kwargs = {"neighbor_mode": "supervised", "fisher_score": True, 'y': y}
    W = construct_W(X, **kwargs)
    # build the diagonal D matrix from affinity matrix W
    D = np.array(W.sum(axis=1), dtype='float32')
    L = W
    tmp = np.dot(np.transpose(D), X)
    D = diags(np.transpose(D), [0])
    Xt = np.transpose(X)
    t1 = np.transpose(np.dot(Xt, D.todense()))
    t2 = np.transpose(np.dot(Xt, L.todense()))
    # compute the numerator of Lr
    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()
    # compute the denominator of Lr
    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()
    # avoid the denominator of Lr to be 0
    D_prime[D_prime < 1e-12] = 10000
    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]

    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1
    score = 1.0/lap_score - 1
    return np.transpose(score)


def feature_ranking(score):
    """
    Rank features in descending order according to fisher score, the larger the fisher score, the more important the
    feature is
    """
    idx = np.argsort(score, 0)
    return idx[::-1]


def main():
    # Prevent csv field size overflow error.
    csv.field_size_limit(sys.maxsize)

    if len(sys.argv) != 3 or len(sys.argv) != 4:
        print(f'Usage: python {sys.argv[0]} <data input file> <data output file> [feature output file]')
        exit()

    X_data = list()
    y_data = list()

    # Get data from CSV file in the format (x, y).
    with open(sys.argv[1], 'rt') as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        for row in csv_reader:
            vector = list(map(int, row[0])) # Parse bitstring to a list of 0's and 1's.
            verdict = int(row[1])
            X_data.append(vector)
            y_data.append(verdict)

    # Compute fisher score.
    score = fisher_score(np.array(X_data, dtype='int8'), np.array(y_data, dtype='int8'))

    # Get the top features by their indices.
    ranked_indices = feature_ranking(score)
    ranked_indices = sorted(ranked_indices[:FISHER_NUM_FEATURES])

    # Only include selected features in our data.
    for i in range(len(X_data)):
        X_data[i] = [X_data[i][j] for j in ranked_indices]

    with open(sys.argv[2], 'wt') as output_file:
        for i in range(len(X_data)):
            output_file.write(''.join(map(str, X_data[i])) + ',' + str(y_data[i]) + '\n')

    if len(sys.argv) == 4:
        # pickle.dump(   , open(sys.argv[3], 'wb'))
        print(f'Saved top features to {sys.argv[3]}')


if __name__ == "__main__":
    main()

