from keras.layers import Dense, Input
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeClassifier


NUM_FOLDS = 10
BATCH_SIZE = 1000
EPOCHS = 100


def get_model():
    input = Input()

    # Stacked autoencoders.
    encoder = Dense(6000, activation='relu')(input)
    encoder = Dense(2000, activation='relu')(encoder)
    encoder = Dense(500,  activation='relu')(encoder)
    decoder = Dense(2000, activation='relu')(encoder)
    decoder = Dense(6000, activation='sigmoid')(decoder)

    model = Model(model.input, model.get_layer('dense_7').output) # TODO: Change dense_7
    dtc_features = model.predict(X_data)  # fit your decision tree on this data
    dtc = DecisionTreeClassifier(criterion = 'entropy')
    # Train the decision tree on the extracted features
    dtc.fit(X, y) # y should be one-dimensional for sklearn


def main():
    if len(sys.args) < 2:
        print('Error')
        exit()

    X_data = []
    y_data = []
    with open(sys.args[1], 'rt') as pickled_data:
        data = pickle.load(pickled_data)
        for row in data:
            X_data.append(row[1:])
            y_data.append(row[0])

    kfold = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1)

    accuracy = []
    precision = []
    recall = []
    auc = []
    num_fp = []
    f1 = []

    for train, test in kfold.split(X_data, y_data):
        evaluate_model(X_data[train], y_data[train], X_data[test], y_date[test])

    # Report model performance.
    print(f'Using {NUM_FOLDS}-fold Cross Validation')
    print(f'Accuracy: {mean(accuracy):.3f}')
    print(f'Precision: {mean(precision):.3f}')
    print(f'Recall: {mean(recall):.3f}')
    print(f'AUC: {mean(auc):.3f}')
    print(f'Number false positives: {mean(num_fp):.3f}')
    print(f'F1 Score: {mean(f1):.3f}')


if __name__ == "__main__":
    main()
