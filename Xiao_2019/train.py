import multiprocessing as mp
from keras.layers import Dense, Input
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeClassifier


NUM_FOLDS = 10
BATCH_SIZE = 1000
EPOCHS = 100


def get_model():
    input = Input()

    # Stacked autoencoders.
    encoder = Dense(6000, activation='relu')(input)
    encoder = Dense(2000, activation='relu')(encoder)
    encoder = Dense(500,  activation='relu')(encoder)
    decoder = Dense(2000, activation='relu')(encoder)
    decoder = Dense(6000, activation='sigmoid')(decoder)

    model = Model(model.input, model.get_layer('dense_7').output) # TODO: Change dense_7
    dtc_features = model.predict(X_data)  # fit your decision tree on this data
    dtc = DecisionTreeClassifier(criterion = 'entropy')
    # Train the decision tree on the extracted features
    dtc.fit(X, y) # y should be one-dimensional for sklearn


def main():
    # Get X and y data here

    kfold = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1)

    manager = mp.Manager()

    accuracy  = manager.list()
    precision = manager.list()
    recall    = manager.list()
    auc       = manager.list()
    num_fp    = manager.list()
    f1        = manager.list()

    pool = mp.Pool(mp.cpu_count())
    for train, test in kfold.split(X_data, y_data):
        pool.apply_async(
            evaluate_model,
            args=(X_data[train], y_data[train], X_data[test], y_data[test],
                  accuracy, precision, recall, auc, num_fp, f1))
    pool.close()
    pool.join()

    # Report model performance.
    print(f'Using {NUM_FOLDS}-fold Cross Validation')
    print(f'Accuracy: {mean(accuracy):.3f}')
    print(f'Precision: {mean(precision):.3f}')
    print(f'Recall: {mean(recall):.3f}')
    print(f'AUC: {mean(auc):.3f}')
    print(f'Number false positives: {mean(num_fp):.3f}')
    print(f'F1 Score: {mean(f1):.3f}')


if __name__ == "__main__":
    main()
