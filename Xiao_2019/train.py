import pickle
import sys
from sklearn.model_selection import KFold
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Input, concatenate
import tensorflow.keras.backend as K
import tensorflow as tf
from sklearn import tree

NUM_FOLDS = 10
BATCH_SIZE = 1000
EPOCHS = 100
LOSS = 'binary_crossentropy'
OPTIMIZER = 'adam'

def main():
    if len(sys.argv) < 2:
        print(f'Usage: python3 {sys.argv[0]} <data pickle>')
        exit()

    X_data = []
    y_data = []
    with open(sys.argv[1], 'rb') as pickled_data:
        data = pickle.load(pickled_data)
        for row in data:
            X_data.append(row[1:])
            y_data.append(row[0])

    kfold = KFold(n_splits=NUM_FOLDS, shuffle=True)

    # accuracy = []
    # precision = []
    # recall = []
    # auc = []
    # num_fp = []
    # f1 = []

    #for train, test in kfold.split(X_data, y_data):
    input_dim = len(X_data[0])

    model = Sequential([
        Dense(input_dim, activation='relu', name='input_layer'),
        Dense(6000, activation='relu', name='6000_layer'),
        Dense(2000, activation='relu', name='2000_layer'),
        Dense(500,  activation='relu', name='500_layer'),
        Dense(2000, activation='relu'),
        Dense(6000, activation='relu'),
        Dense(input_dim, activation='relu')
    ])
    model.compile(loss=LOSS, optimizer=OPTIMIZER)
    model.fit(X_data, X_data, batch_size=BATCH_SIZE, epochs=EPOCHS)
    model.save('model.h5')
    
    new_model = Sequential([
        Dense(input_dim, activation='relu', name='input_layer'),
        Dense(6000, activation='relu', name='6000_layer'),
        Dense(2000, activation='relu', name='2000_layer'),
        Dense(500,  activation='relu', name='500_layer')
    ])
    new_model.build(input_shape=(input_dim, input_dim))
    new_model.compile(loss=LOSS, optimizer=OPTIMIZER)
    new_model.load_weights('model.h5', by_name=True)
    sae_output = new_model.predict(X_data)

    dtc = tree.DecisionTreeClassifier()
    dtc.fit(sae_output, y_data)

    # Try all 6000-2000-500-2000-6000 at once
    # Save
    # Delete decoders
    # Predict with all data
    # Feed to DT classifier

    # # Report model performance.
    # print(f'Using {NUM_FOLDS}-fold Cross Validation')
    # print(f'Accuracy: {mean(accuracy):.3f}')
    # print(f'Precision: {mean(precision):.3f}')
    # print(f'Recall: {mean(recall):.3f}')
    # print(f'AUC: {mean(auc):.3f}')
    # print(f'Number false positives: {mean(num_fp):.3f}')
    # print(f'F1 Score: {mean(f1):.3f}')


if __name__ == "__main__":
    main()
