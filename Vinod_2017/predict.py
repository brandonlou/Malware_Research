import csv
import os
import pickle
import sys
from collections import Counter
from sklearn.metrics import accuracy_score

if len(sys.argv) != 4:
    print('USAGE: python %s <preprocessed dir> <tf-idf file> <model file>' % sys.argv[0])
    exit()

feature_info = pickle.load(open(sys.argv[2], 'rb'))
sorted_scores = feature_info[0]
IDF = feature_info[1]

X_data = list()
y_data = list()

# Go through each preprocessed report.
input_dir = sys.argv[1]
for filename in os.listdir(input_dir):
    with open(input_dir + '/' + filename) as infile:
        try:
            lines = infile.read().splitlines()
        except:
            continue

    # Get the verdict of the report.
    verdict = int(lines[0])
    if verdict not in (0, 1):
        print('Error: First line of %s not 0 or 1' % filename)
        exit()

    # Get API call that occurs most in this report.
    counter = Counter(lines)
    max_occurance = counter.most_common()[0][1]

    # Build the TF-IDF vector.
    vector = list()
    for feature in sorted_scores:
        feature = feature[0] # We only want the API name.
        TF = counter[feature] / max_occurance
        vector.append(TF * IDF[feature])

    X_data.append(vector)
    y_data.append(verdict)

    print('Info: Processed %s.' % filename)

# Load model and predict.
model = pickle.load(open(sys.argv[3], 'rb'))
y_pred = model.predict(X_data)

print('Actual:', y_data)
print('Predicted:', y_pred)
print('Accuracy:', accuracy_score(y_pred, y_data))
